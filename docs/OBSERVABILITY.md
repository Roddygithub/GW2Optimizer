# Observability Guide

Guide complet pour monitorer GW2Optimizer en production.

## ðŸ“Š Stack d'ObservabilitÃ©

### Composants
- **Prometheus** : Collecte de mÃ©triques
- **Grafana** : Visualisation et dashboards
- **Sentry** : Error tracking et performance monitoring
- **Structlog** : Structured logging (JSON)

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI   â”‚
â”‚  Backend    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚              â”‚
       â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Prometheus  â”‚  â”‚   Sentry    â”‚
â”‚  /metrics   â”‚  â”‚   Errors    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Grafana   â”‚
â”‚  Dashboard  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸš€ Quick Start

### 1. DÃ©marrer Prometheus + Grafana

```bash
# CrÃ©er docker-compose.monitoring.yml
cd GW2Optimizer
docker-compose -f docker-compose.monitoring.yml up -d
```

### 2. Configuration Prometheus

CrÃ©er `prometheus.yml` :

```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'gw2optimizer'
    static_configs:
      - targets: ['host.docker.internal:8000']
    metrics_path: '/metrics'
```

### 3. AccÃ©der aux Dashboards

- **Prometheus** : http://localhost:9090
- **Grafana** : http://localhost:3000 (admin/admin)
- **MÃ©triques Backend** : http://localhost:8000/metrics

## ðŸ“ˆ MÃ©triques Disponibles

### HTTP Metrics (Auto)
Fournies par `prometheus-fastapi-instrumentator` :

- `http_requests_total` - Total des requÃªtes HTTP
- `http_request_duration_seconds` - DurÃ©e des requÃªtes (histogramme)
- `http_requests_in_progress` - RequÃªtes en cours
- `http_request_size_bytes` - Taille des requÃªtes
- `http_response_size_bytes` - Taille des rÃ©ponses

### Custom AI Metrics

```python
# Utilisation dans le code
from app.core.metrics import track_ai_request

track_ai_request(
    model="mistral",
    operation="compose_team",
    duration=2.5,
    status="success",
    tokens_prompt=150,
    tokens_completion=300,
)
```

**MÃ©triques** :
- `gw2_ai_requests_total{model, operation, status}` - Total requÃªtes IA
- `gw2_ai_request_duration_seconds{model, operation}` - DurÃ©e requÃªtes IA
- `gw2_ai_tokens_used_total{model, token_type}` - Tokens utilisÃ©s
- `gw2_ai_feedback_total{result}` - Feedbacks soumis
- `gw2_ai_training_triggers_total{result}` - EntraÃ®nements dÃ©clenchÃ©s

### Database Metrics

```python
from app.core.metrics import track_db_query

track_db_query(
    operation="select",
    table="builds",
    duration=0.05,
)
```

**MÃ©triques** :
- `gw2_db_query_duration_seconds{operation, table}` - DurÃ©e queries
- `gw2_db_connections_active` - Connexions actives
- `gw2_db_errors_total{operation, error_type}` - Erreurs DB

### Cache Metrics

```python
from app.core.metrics import track_cache_operation

track_cache_operation(operation="get", result="hit")
```

**MÃ©triques** :
- `gw2_cache_operations_total{operation, result}` - OpÃ©rations cache
- `gw2_cache_hit_rate` - Taux de hit cache (0-1)
- `gw2_cache_size_bytes` - Taille du cache

### External API Metrics

```python
from app.core.metrics import track_external_api

track_external_api(
    service="gw2api",
    endpoint="/v2/builds",
    duration=0.8,
    status="200",
)
```

**MÃ©triques** :
- `gw2_external_api_requests_total{service, endpoint, status}` - RequÃªtes externes
- `gw2_external_api_duration_seconds{service, endpoint}` - DurÃ©e API externes

### Business Metrics

- `gw2_builds_created_total{profession, game_mode}` - Builds crÃ©Ã©s
- `gw2_teams_created_total{game_mode, size}` - Teams crÃ©Ã©es
- `gw2_users_active` - Utilisateurs actifs (24h)

### Application Info

- `gw2_app_info{version, environment}` - Info application

## ðŸ“Š Dashboards Grafana

### Dashboard 1 : System Overview

**Panels** :
1. **Request Rate** (Graph)
   ```promql
   rate(http_requests_total[5m])
   ```

2. **Error Rate** (Graph)
   ```promql
   rate(http_requests_total{status=~"5.."}[5m])
   ```

3. **Response Time P95** (Graph)
   ```promql
   histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))
   ```

4. **Active Users** (Stat)
   ```promql
   gw2_users_active
   ```

### Dashboard 2 : AI Performance

**Panels** :
1. **AI Requests by Model** (Graph)
   ```promql
   rate(gw2_ai_requests_total[5m])
   ```

2. **AI Request Duration P95** (Graph)
   ```promql
   histogram_quantile(0.95, rate(gw2_ai_request_duration_seconds_bucket[5m]))
   ```

3. **Tokens Used** (Graph)
   ```promql
   rate(gw2_ai_tokens_used_total[5m])
   ```

4. **AI Feedback Rate** (Graph)
   ```promql
   rate(gw2_ai_feedback_total[5m])
   ```

### Dashboard 3 : Database & Cache

**Panels** :
1. **DB Query Duration P95** (Graph)
   ```promql
   histogram_quantile(0.95, rate(gw2_db_query_duration_seconds_bucket[5m]))
   ```

2. **DB Connections** (Graph)
   ```promql
   gw2_db_connections_active
   ```

3. **Cache Hit Rate** (Gauge)
   ```promql
   gw2_cache_hit_rate
   ```

4. **Cache Operations** (Graph)
   ```promql
   rate(gw2_cache_operations_total[5m])
   ```

## ðŸ” Structured Logging

### Configuration

Le backend utilise `structlog` pour des logs JSON structurÃ©s :

```python
from app.core.logging import logger

# Log simple
logger.info("User logged in", user_id=123, username="player1")

# Log avec contexte
logger.warning(
    "Slow AI request",
    model="mistral",
    duration=5.2,
    operation="compose_team",
)

# Log d'erreur
logger.error(
    "Database connection failed",
    error=str(e),
    retry_count=3,
)
```

### Format des Logs

**Development** (console colorÃ©e) :
```
2024-11-15T10:00:00.123Z [info     ] User logged in user_id=123 username=player1
```

**Production** (JSON) :
```json
{
  "event": "User logged in",
  "level": "info",
  "timestamp": "2024-11-15T10:00:00.123Z",
  "user_id": 123,
  "username": "player1"
}
```

### AgrÃ©gation des Logs

Pour agrÃ©ger les logs en production, utilisez :
- **Loki** (recommandÃ©, intÃ©gration Grafana native)
- **ELK Stack** (Elasticsearch + Logstash + Kibana)
- **CloudWatch Logs** (AWS)

## ðŸš¨ Alerting

### Alertes Critiques (PagerDuty/Slack)

1. **Error Rate > 5%**
   ```yaml
   alert: HighErrorRate
   expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) > 0.05
   for: 5m
   annotations:
     summary: "High error rate detected"
   ```

2. **Response Time P95 > 2s**
   ```yaml
   alert: SlowResponses
   expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 2
   for: 5m
   ```

3. **Database Down**
   ```yaml
   alert: DatabaseDown
   expr: gw2_db_connections_active == 0
   for: 1m
   ```

### Alertes Warning (Email)

1. **Error Rate > 1%**
2. **Response Time P95 > 1s**
3. **Cache Hit Rate < 50%**
4. **Disk Usage > 80%**

## ðŸ› Sentry Error Tracking

### Configuration

```bash
# Backend .env
SENTRY_DSN=https://xxx@sentry.io/xxx
ENVIRONMENT=production
```

### Utilisation

Sentry capture automatiquement :
- âœ… Exceptions non gÃ©rÃ©es
- âœ… Erreurs HTTP 5xx
- âœ… Performance traces (10% sample)

**Capture manuelle** :
```python
import sentry_sdk

try:
    risky_operation()
except Exception as e:
    sentry_sdk.capture_exception(e)
```

**Ajouter contexte** :
```python
with sentry_sdk.configure_scope() as scope:
    scope.set_user({"id": user_id, "username": username})
    scope.set_tag("game_mode", "WvW")
    scope.set_context("build", {"profession": "Guardian"})
```

## ðŸ“‹ Checklist Production

Avant de dÃ©ployer en production :

- [ ] Prometheus configurÃ© et scraping `/metrics`
- [ ] Grafana dashboards crÃ©Ã©s et testÃ©s
- [ ] Sentry DSN configurÃ©
- [ ] Alertes configurÃ©es (Slack/Email)
- [ ] Logs structurÃ©s activÃ©s (JSON)
- [ ] Log aggregation configurÃ©e (Loki/ELK)
- [ ] Runbook crÃ©Ã© pour rÃ©pondre aux alertes
- [ ] Ã‰quipe formÃ©e sur les outils

## ðŸ”§ Troubleshooting

### Prometheus ne scrape pas les mÃ©triques

```bash
# VÃ©rifier que /metrics est accessible
curl http://localhost:8000/metrics

# VÃ©rifier la config Prometheus
docker-compose -f docker-compose.monitoring.yml logs prometheus
```

### Grafana ne se connecte pas Ã  Prometheus

1. Aller dans Configuration > Data Sources
2. Ajouter Prometheus : `http://prometheus:9090`
3. Tester la connexion

### Logs non structurÃ©s

```bash
# VÃ©rifier que structlog est installÃ©
poetry show structlog

# VÃ©rifier les logs
tail -f backend/logs/app.log
```

## ðŸ“š Ressources

- [Prometheus Docs](https://prometheus.io/docs/)
- [Grafana Dashboards](https://grafana.com/grafana/dashboards/)
- [Sentry Python SDK](https://docs.sentry.io/platforms/python/)
- [Structlog Docs](https://www.structlog.org/)

## ðŸŽ¯ SLOs (Service Level Objectives)

### Targets

- **Availability** : 99.9% uptime
- **Latency P95** : < 200ms
- **Latency P99** : < 500ms
- **Error Rate** : < 1%
- **AI Request Success** : > 95%

### Monitoring

Suivre ces SLOs dans Grafana et configurer des alertes si les targets ne sont pas atteints.
