# GW2Optimizer v1.1.0 - Guide des Nouvelles Fonctionnalit√©s

## üìã Table des Mati√®res

1. [Parser GW2Skill Complet](#1-parser-gw2skill-complet)
2. [Scraping Communautaire](#2-scraping-communautaire)
3. [Analyse des Synergies](#3-analyse-des-synergies)
4. [Export Snowcrows](#4-export-snowcrows)
5. [Exemples d'Utilisation](#5-exemples-dutilisation)

---

## 1. Parser GW2Skill Complet

### Fonctionnalit√©s

Le parser GW2Skill peut maintenant extraire **toutes les informations** d'un build depuis n'importe quel format d'URL GW2Skills.

#### Formats d'URL Support√©s

```
‚úÖ https://gw2skills.net/editor/...
‚úÖ https://en.gw2skills.net/editor/...
‚úÖ https://fr.gw2skills.net/editor/...
‚úÖ https://de.gw2skills.net/editor/...
‚úÖ http://gw2skills.net/editor/... (converti en https)
‚úÖ gw2skills.net/editor/... (https ajout√© automatiquement)
```

#### Donn√©es Extraites

- **Nom du build** (depuis title ou meta tags)
- **Profession** (9 professions support√©es)
- **Sp√©cialisation** (27 √©lites support√©es)
- **Trait lines** (extraction depuis JavaScript)
- **Skills** (Heal, 3 Utilities, Elite)
- **Equipment** (Armor, Trinkets, Weapons)
- **Stats** (30+ combinaisons: Berserker, Minstrel, Viper, etc.)

### Utilisation via API

```bash
# Parser un lien GW2Skill
curl -X POST http://localhost:8000/api/v1/builds/parse \
  -H "Content-Type: application/json" \
  -d '{"url": "https://gw2skills.net/editor/..."}'
```

### Utilisation Python

```python
from app.services.parser.gw2skill_parser import GW2SkillParser

parser = GW2SkillParser()
build = await parser.parse_url("https://gw2skills.net/editor/...")

print(f"Build: {build.name}")
print(f"Profession: {build.profession}")
print(f"Traits: {len(build.trait_lines)} lines")
print(f"Skills: {len(build.skills)} skills")
```

### Donn√©es GW2 Int√©gr√©es

Le parser utilise une base de donn√©es compl√®te :

- **27 Sp√©cialisations √©lites** (Dragonhunter, Firebrand, Willbender, etc.)
- **30+ Combinaisons de stats** (Power, Condi, Support, Tank)
- **Runes et Sigils** (Scholar, Eagle, Force, Impact, etc.)
- **Types d'armes** (Tous les types GW2)

---

## 2. Scraping Communautaire

### Sources Int√©gr√©es

Le scraper collecte automatiquement les builds depuis les sites communautaires majeurs.

#### Snowcrows (Raids)
- URL: https://snowcrows.com/builds
- Focus: Builds raid optimis√©s
- Game Mode: `raid_guild`

#### MetaBattle (WvW)
- URL: https://metabattle.com/wiki/WvW
- Focus: Builds WvW vari√©s
- Game Modes: `zerg`, `roaming` (d√©tection auto)

#### Hardstuck (WvW)
- URL: https://hardstuck.gg/gw2/builds/
- Focus: Builds WvW sp√©cialis√©s
- Game Mode: `zerg`

### Fonctionnalit√©s

‚úÖ **Extraction automatique** de la profession depuis le nom du build  
‚úÖ **D√©tection du r√¥le** (DPS, Support, Tank, Boonshare)  
‚úÖ **Suppression des doublons** (m√™me nom + profession)  
‚úÖ **Collecte automatique** dans le pipeline d'apprentissage  
‚úÖ **Ex√©cution en background** (non-bloquant)

### Utilisation via API

```bash
# D√©clencher le scraping
curl -X POST http://localhost:8000/api/v1/scraper/run

# Lister les sources
curl http://localhost:8000/api/v1/scraper/sources
```

### Utilisation Python

```python
from app.services.scraper.community_scraper import CommunityScraper

scraper = CommunityScraper()

# Scraper toutes les sources
builds = await scraper.scrape_all_sources()
print(f"Scraped {len(builds)} builds")

# Scraper une source sp√©cifique
snowcrows_builds = await scraper.scrape_snowcrows()
metabattle_builds = await scraper.scrape_metabattle()
hardstuck_builds = await scraper.scrape_hardstuck()
```

### Int√©gration Learning Pipeline

Tous les builds scrap√©s sont **automatiquement collect√©s** pour l'apprentissage :

```python
# Automatique lors du scraping
for build in scraped_builds:
    await collector.collect_build(build, DataSource.COMMUNITY_SCRAPE)
```

---

## 3. Analyse des Synergies

### Capacit√©s d'Analyse

L'analyseur de synergies √©value les builds et √©quipes selon **7 m√©triques d√©taill√©es**.

#### Pour un Build Individuel

```python
from app.services.synergy_analyzer import SynergyAnalyzer

analyzer = SynergyAnalyzer()
analysis = analyzer.analyze_build(build)

# R√©sultats
{
    "boons_provided": ["might", "fury", "quickness", ...],
    "role_effectiveness": 8.5,  # 0-10
    "synergy_potential": 7.0,   # 0-10
    "strengths": [
        "Provides critical boons (Quickness/Alacrity)",
        "Strong defensive support"
    ],
    "weaknesses": [
        "Lower mobility in WvW"
    ]
}
```

#### Pour une √âquipe

```python
# Analyse compl√®te
synergies = analyzer.analyze_team(team)
scores = analyzer.calculate_team_score(team)

# Scores d√©taill√©s
{
    "boon_coverage": 8.5,        # Couverture des boons
    "role_balance": 7.0,         # Balance des r√¥les
    "profession_diversity": 9.0, # Diversit√© professions
    "synergy_strength": 8.0,     # Force des synergies
    "survivability": 7.5,        # Survie
    "damage_potential": 8.0,     # Potentiel d√©g√¢ts
    "utility": 7.0,              # Utilit√© (CC, cleanse)
    "overall": 7.9               # Score global (moyenne)
}
```

### Boons Analys√©s

Le syst√®me analyse **11 types de boons** :

- **Critiques** : Might, Fury, Quickness, Alacrity
- **D√©fensifs** : Protection, Aegis, Stability, Resistance
- **Utilitaires** : Regeneration, Vigor, Swiftness

### Synergies D√©tect√©es

- **Boons** : Couverture compl√®te des boons critiques
- **R√¥les** : Distribution √©quilibr√©e Tank/Support/DPS
- **Professions** : Diversit√© et compl√©mentarit√©
- **Combos** : Potentiel de combo fields (√† venir)

### Int√©gration Automatique

L'analyseur est **automatiquement utilis√©** lors de l'optimisation d'√©quipe :

```python
# Dans TeamService
team = await self.optimize_team(request)
# ‚Üì Analyse automatique
synergies = await self._analyze_synergies(team)
# ‚Üì Scores calcul√©s
team.overall_rating = scores["overall"]
team.strengths = ["Excellent boon coverage", ...]
team.weaknesses = ["Low survivability", ...]
```

---

## 4. Export Snowcrows

### Formats d'Export

Le syst√®me peut exporter les builds dans **2 formats** compatibles Snowcrows.

#### Format JSON

Structure compl√®te avec toutes les m√©tadonn√©es :

```json
{
  "name": "Guardian Firebrand Support",
  "profession": "Guardian",
  "specialization": "Firebrand",
  "traits": [...],
  "skills": [...],
  "equipment": [...],
  "metadata": {
    "game_mode": "zerg",
    "role": "support",
    "source": "snowcrows",
    "effectiveness": 8.5,
    "difficulty": 3,
    "exported_at": "2025-10-20T01:00:00Z"
  },
  "description": "...",
  "synergies": [...],
  "counters": [...]
}
```

#### Format HTML

Page web compl√®te avec **CSS Snowcrows** int√©gr√© :

- Design moderne aux couleurs GW2
- Sections : Header, Traits, Skills, Equipment, Description
- Responsive et pr√™t √† partager
- Style identique √† Snowcrows

### Utilisation via API

```bash
# Export JSON
curl http://localhost:8000/api/v1/export/build/{build_id}/json

# Export HTML
curl http://localhost:8000/api/v1/export/build/{build_id}/html > build.html

# Export √©quipe JSON
curl http://localhost:8000/api/v1/export/team/{team_id}/json
```

### Utilisation Python

```python
from app.services.exporter.snowcrows_exporter import SnowcrowsExporter

exporter = SnowcrowsExporter()

# Export JSON
json_data = exporter.export_build_json(build)

# Export HTML
html_content = exporter.export_build_html(build)
with open("build.html", "w") as f:
    f.write(html_content)

# Export √©quipe
team_json = exporter.export_team_json(team)
```

### Personnalisation CSS

Le CSS peut √™tre personnalis√© via `_get_snowcrows_css()` :

- Couleurs GW2 (#c89b3c gold, #1e3a8a blue)
- Gradients et ombres
- Badges et ic√¥nes
- Responsive design

---

## 5. Exemples d'Utilisation

### Workflow Complet

```python
# 1. Parser un build GW2Skill
parser = GW2SkillParser()
build = await parser.parse_url("https://gw2skills.net/editor/...")

# 2. Analyser le build
analyzer = SynergyAnalyzer()
analysis = analyzer.analyze_build(build)
print(f"Role effectiveness: {analysis['role_effectiveness']}/10")

# 3. Cr√©er une √©quipe
team = TeamComposition(
    name="My WvW Squad",
    game_mode=GameMode.ZERG,
    team_size=25
)

# Ajouter des builds
team.slots = [
    TeamSlot(slot_number=i, build=build)
    for i, build in enumerate(builds)
]

# 4. Analyser l'√©quipe
synergies = analyzer.analyze_team(team)
scores = analyzer.calculate_team_score(team)
print(f"Team rating: {scores['overall']}/10")

# 5. Exporter
exporter = SnowcrowsExporter()
html = exporter.export_build_html(build)
```

### Scraping Automatique

```python
# Script de scraping quotidien
async def daily_scraping():
    scraper = CommunityScraper()
    collector = DataCollector()
    
    # Scraper toutes les sources
    builds = await scraper.scrape_all_sources()
    
    # Collecter pour apprentissage
    for build in builds:
        await collector.collect_build(build, DataSource.COMMUNITY_SCRAPE)
    
    print(f"‚úÖ Collected {len(builds)} builds")
```

### Pipeline Complet

```python
# Pipeline d'optimisation d'√©quipe
async def optimize_wvw_team(size: int):
    # 1. Scraper les meilleurs builds
    scraper = CommunityScraper()
    builds = await scraper.scrape_all_sources()
    
    # 2. Filtrer par WvW
    wvw_builds = [b for b in builds if b.game_mode in [GameMode.ZERG, GameMode.ROAMING]]
    
    # 3. Analyser chaque build
    analyzer = SynergyAnalyzer()
    for build in wvw_builds:
        analysis = analyzer.analyze_build(build)
        build.effectiveness = analysis['role_effectiveness']
    
    # 4. S√©lectionner les meilleurs
    best_builds = sorted(wvw_builds, key=lambda b: b.effectiveness, reverse=True)[:size]
    
    # 5. Cr√©er l'√©quipe
    team = TeamComposition(name="Optimized Squad", game_mode=GameMode.ZERG, team_size=size)
    team.slots = [TeamSlot(slot_number=i, build=b) for i, b in enumerate(best_builds)]
    
    # 6. Analyser l'√©quipe
    synergies = analyzer.analyze_team(team)
    scores = analyzer.calculate_team_score(team)
    
    # 7. Exporter
    exporter = SnowcrowsExporter()
    team_json = exporter.export_team_json(team)
    
    return team, scores
```

---

## üìä M√©triques de Performance

| Op√©ration | Temps Moyen | Notes |
|-----------|-------------|-------|
| Parser GW2Skill | 1-2s | D√©pend de la connexion |
| Scraper (1 source) | 5-10s | 20 builds max par source |
| Analyse build | <50ms | Instantan√© |
| Analyse √©quipe | <100ms | M√™me pour 50 joueurs |
| Export JSON | <10ms | Tr√®s rapide |
| Export HTML | <50ms | G√©n√©ration CSS incluse |

---

## üîß Configuration

### Variables d'Environnement

```bash
# Scraper
SCRAPER_USER_AGENT=GW2Optimizer/1.1.0
SCRAPER_UPDATE_INTERVAL=604800  # 7 jours

# Parser
PARSER_TIMEOUT=15  # secondes
PARSER_FOLLOW_REDIRECTS=true
```

### Limites

```python
# Dans community_scraper.py
MAX_BUILDS_PER_SOURCE = 20  # Limite par source

# Dans gw2skill_parser.py
PARSER_TIMEOUT = 15.0  # secondes
```

---

## üêõ D√©pannage

### Parser ne trouve pas les traits

**Cause** : Structure JavaScript de GW2Skills a chang√©  
**Solution** : Le parser cr√©e des placeholders, les donn√©es de base sont extraites

### Scraper retourne 0 builds

**Cause** : Site bloque le user-agent ou est down  
**Solution** : V√©rifier `SCRAPER_USER_AGENT`, tester manuellement l'URL

### Export HTML ne s'affiche pas correctement

**Cause** : CSS non charg√©  
**Solution** : Le CSS est inline, v√©rifier le navigateur

---

## üìö Ressources

- [API Documentation](../API.md)
- [Architecture](../ARCHITECTURE.md)
- [Changelog v1.1.0](../../CHANGELOG_v1.1.0.md)
- [Tests](../../backend/tests/)

---

**Version**: 1.1.0  
**Date**: 20 Octobre 2025  
**Auteur**: Roddy  
**Licence**: MIT
