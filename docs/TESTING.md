# Guide de test pour GW2Optimizer v1.2.0

## ğŸ“‹ Table des matiÃ¨res

- [Introduction](#introduction)
- [Structure des tests](#structure-des-tests)
- [Installation](#installation)
- [ExÃ©cution des tests](#exÃ©cution-des-tests)
- [Couverture de code](#couverture-de-code)
- [Tests unitaires](#tests-unitaires)
- [Tests d'API](#tests-dapi)
- [Tests d'intÃ©gration](#tests-dintÃ©gration)
- [CI/CD](#cicd)
- [DÃ©pannage](#dÃ©pannage)

## Introduction

Ce guide dÃ©crit comment exÃ©cuter et maintenir la suite de tests pour GW2Optimizer. Notre objectif est de maintenir une couverture de code **â‰¥ 80%** avec des tests rÃ©els utilisant PostgreSQL et Redis.

## Structure des tests

```
backend/tests/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ conftest.py                    # Fixtures partagÃ©es
â”œâ”€â”€ test_services/                 # Tests unitaires des services
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_build_service.py     # Tests BuildService
â”‚   â””â”€â”€ test_team_service.py      # Tests TeamService
â”œâ”€â”€ test_api/                      # Tests des endpoints API
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_builds.py            # Tests API builds
â”‚   â””â”€â”€ test_teams.py             # Tests API teams
â””â”€â”€ test_integration/              # Tests d'intÃ©gration
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ test_auth_flow.py         # Tests flux d'authentification
    â””â”€â”€ test_cache_flow.py        # Tests cache Redis
```

## Installation

### PrÃ©requis

- Python 3.11+
- PostgreSQL 14+ (optionnel, SQLite utilisÃ© par dÃ©faut pour les tests)
- Redis 6+ (optionnel, fakeredis utilisÃ© par dÃ©faut)
- Docker (recommandÃ© pour les services)

### Installation des dÃ©pendances

```bash
cd backend

# Installer les dÃ©pendances de production
pip install -r requirements.txt

# Installer les dÃ©pendances de dÃ©veloppement
pip install -r requirements-dev.txt
```

### Configuration de l'environnement de test

```bash
# Copier le fichier d'exemple
cp .env.example .env.test

# Ã‰diter .env.test avec vos paramÃ¨tres de test
# Pour les tests locaux, SQLite en mÃ©moire est utilisÃ© par dÃ©faut
```

## ExÃ©cution des tests

### Tous les tests

```bash
cd backend
pytest
```

### Tests avec couverture

```bash
# Rapport en terminal
pytest --cov=app --cov-report=term-missing

# Rapport HTML
pytest --cov=app --cov-report=html

# Rapport XML (pour CI/CD)
pytest --cov=app --cov-report=xml

# VÃ©rifier la couverture minimale (80%)
pytest --cov=app --cov-fail-under=80
```

### Tests par catÃ©gorie

```bash
# Tests unitaires des services
pytest tests/test_services/ -v

# Tests d'API
pytest tests/test_api/ -v

# Tests d'intÃ©gration
pytest tests/test_integration/ -v -m integration
```

### Tests spÃ©cifiques

```bash
# Un fichier de test
pytest tests/test_services/test_build_service.py -v

# Une classe de test
pytest tests/test_services/test_build_service.py::TestBuildService -v

# Un test spÃ©cifique
pytest tests/test_services/test_build_service.py::TestBuildService::test_create_build_success -v
```

### Tests avec marqueurs

```bash
# Tests unitaires uniquement
pytest -m unit

# Tests d'intÃ©gration uniquement
pytest -m integration

# Exclure les tests lents
pytest -m "not slow"
```

### Tests en parallÃ¨le

```bash
# ExÃ©cuter sur 4 processus
pytest -n 4

# Auto-dÃ©tection du nombre de CPU
pytest -n auto
```

## Couverture de code

### Objectif de couverture

- **Minimum requis** : 80%
- **Objectif** : 90%+
- **IdÃ©al** : 95%+

### Visualiser la couverture

```bash
# GÃ©nÃ©rer le rapport HTML
pytest --cov=app --cov-report=html

# Ouvrir le rapport dans le navigateur
open htmlcov/index.html  # macOS
xdg-open htmlcov/index.html  # Linux
start htmlcov/index.html  # Windows
```

### Rapport de couverture dÃ©taillÃ©

```bash
# Voir les lignes manquantes
pytest --cov=app --cov-report=term-missing

# Rapport par fichier
pytest --cov=app --cov-report=term:skip-covered
```

## Tests unitaires

### BuildService

Les tests couvrent :
- âœ… CrÃ©ation de builds
- âœ… RÃ©cupÃ©ration par ID (propriÃ©taire/public)
- âœ… Listage avec filtres (profession, game_mode, role)
- âœ… Mise Ã  jour (autorisations)
- âœ… Suppression (autorisations)
- âœ… Comptage et pagination
- âœ… Validation des permissions

**Exemple d'exÃ©cution** :
```bash
pytest tests/test_services/test_build_service.py -v
```

### TeamService

Les tests couvrent :
- âœ… CrÃ©ation de teams
- âœ… Ajout/retrait de builds
- âœ… Gestion des slots
- âœ… Validation des builds (public/privÃ©)
- âœ… Auto-incrÃ©mentation des slot_number
- âœ… Cascade delete

**Exemple d'exÃ©cution** :
```bash
pytest tests/test_services/test_team_service.py -v
```

## Tests d'API

### Endpoints Builds

Tests des endpoints :
- `POST /api/v1/builds` - CrÃ©ation
- `GET /api/v1/builds` - Liste utilisateur
- `GET /api/v1/builds/public/all` - Liste publique
- `GET /api/v1/builds/{id}` - RÃ©cupÃ©ration
- `PUT /api/v1/builds/{id}` - Mise Ã  jour
- `DELETE /api/v1/builds/{id}` - Suppression
- `GET /api/v1/builds/stats/count` - Statistiques

**ScÃ©narios testÃ©s** :
- âœ… Authentification requise
- âœ… Validation des donnÃ©es
- âœ… Permissions propriÃ©taire
- âœ… AccÃ¨s public
- âœ… Filtres et pagination

**Exemple d'exÃ©cution** :
```bash
pytest tests/test_api/test_builds.py -v
```

### Endpoints Teams

Tests similaires pour les endpoints teams avec gestion des slots.

**Exemple d'exÃ©cution** :
```bash
pytest tests/test_api/test_teams.py -v
```

## Tests d'intÃ©gration

### Flux d'authentification

Tests du workflow complet :
1. Inscription (`POST /api/v1/auth/register`)
2. Connexion (`POST /api/v1/auth/login`)
3. AccÃ¨s aux endpoints protÃ©gÃ©s
4. Refresh token
5. Logout

**ScÃ©narios testÃ©s** :
- âœ… Workflow complet register â†’ login â†’ access
- âœ… Credentials invalides
- âœ… Tokens invalides
- âœ… Refresh token
- âœ… Isolation des ressources entre utilisateurs

**Exemple d'exÃ©cution** :
```bash
pytest tests/test_integration/test_auth_flow.py -v
```

### Cache Redis

Tests du systÃ¨me de cache :
- âœ… Mise en cache des builds/teams
- âœ… Invalidation sur update/delete
- âœ… Fallback disque si Redis indisponible
- âœ… Cache avec filtres
- âœ… TTL et expiration
- âœ… AccÃ¨s concurrent

**Exemple d'exÃ©cution** :
```bash
pytest tests/test_integration/test_cache_flow.py -v
```

## CI/CD

### GitHub Actions

Le pipeline CI/CD s'exÃ©cute automatiquement sur :
- Push sur `main` ou `dev`
- Pull requests vers `main` ou `dev`

### Ã‰tapes du pipeline

1. **Lint Backend**
   - Black (formatage)
   - Flake8 (style)
   - isort (imports)
   - MyPy (types)

2. **Test Backend**
   - Services PostgreSQL et Redis
   - Tests unitaires
   - Tests d'API
   - Tests d'intÃ©gration
   - Couverture â‰¥ 80%

3. **Upload Coverage**
   - Rapport vers Codecov
   - Artefact HTML

### ExÃ©cution locale du pipeline

```bash
# Installer act (https://github.com/nektos/act)
brew install act  # macOS
# ou
curl https://raw.githubusercontent.com/nektos/act/master/install.sh | sudo bash

# ExÃ©cuter le workflow localement
act -j test-backend
```

### Variables d'environnement CI

Les secrets suivants doivent Ãªtre configurÃ©s dans GitHub :
- `CODECOV_TOKEN` - Token Codecov pour upload de couverture
- `DB_USER` - Utilisateur PostgreSQL (pour learning pipeline)
- `DB_PASSWORD` - Mot de passe PostgreSQL
- `DB_NAME` - Nom de la base de donnÃ©es
- `DATABASE_URL` - URL complÃ¨te de connexion
- `REDIS_URL` - URL Redis
- `SECRET_KEY` - ClÃ© secrÃ¨te JWT

## DÃ©pannage

### Erreurs de base de donnÃ©es

**ProblÃ¨me** : `sqlalchemy.exc.OperationalError: could not connect to server`

**Solution** :
```bash
# VÃ©rifier que PostgreSQL est dÃ©marrÃ©
pg_isready

# Ou utiliser SQLite pour les tests (par dÃ©faut)
export TEST_DATABASE_URL="sqlite+aiosqlite:///:memory:"
```

### Erreurs Redis

**ProblÃ¨me** : `redis.exceptions.ConnectionError`

**Solution** :
```bash
# VÃ©rifier que Redis est dÃ©marrÃ©
redis-cli ping

# Ou dÃ©sactiver Redis pour les tests
export REDIS_ENABLED=false
```

### Erreurs de couverture

**ProblÃ¨me** : `Coverage is below 80%`

**Solution** :
```bash
# Voir les lignes non couvertes
pytest --cov=app --cov-report=term-missing

# Ajouter des tests pour les fichiers manquants
```

### Tests qui Ã©chouent de maniÃ¨re intermittente

**ProblÃ¨me** : Tests qui passent parfois et Ã©chouent parfois

**Solutions** :
1. VÃ©rifier les dÃ©pendances entre tests
2. Utiliser des fixtures isolÃ©es
3. Ã‰viter les sleep() - utiliser des attentes explicites
4. VÃ©rifier les transactions de base de donnÃ©es

### ProblÃ¨mes de fixtures

**ProblÃ¨me** : `fixture 'db_session' not found`

**Solution** :
```bash
# VÃ©rifier que conftest.py est prÃ©sent
ls tests/conftest.py

# VÃ©rifier les imports
pytest --fixtures
```

### Nettoyage aprÃ¨s les tests

```bash
# Supprimer les fichiers de cache
find . -type d -name __pycache__ -exec rm -rf {} +
find . -type f -name "*.pyc" -delete

# Supprimer les rapports de couverture
rm -rf htmlcov/ .coverage coverage.xml

# Supprimer les bases de donnÃ©es de test
rm -f test.db
```

## Bonnes pratiques

### Ã‰criture de tests

1. **Nommage** : `test_<action>_<scenario>`
   ```python
   def test_create_build_success()
   def test_create_build_unauthorized()
   ```

2. **AAA Pattern** : Arrange, Act, Assert
   ```python
   async def test_example():
       # Arrange
       user = await create_test_user()
       
       # Act
       result = await service.do_something(user)
       
       # Assert
       assert result is not None
   ```

3. **Isolation** : Chaque test doit Ãªtre indÃ©pendant
   ```python
   @pytest_asyncio.fixture
   async def db_session():
       # Nouvelle session pour chaque test
       async with TestSessionLocal() as session:
           yield session
           await session.rollback()
   ```

4. **Fixtures** : RÃ©utiliser les fixtures communes
   ```python
   @pytest.fixture
   def sample_build_data():
       return {"name": "Test", ...}
   ```

### Performance des tests

- Utiliser SQLite en mÃ©moire pour les tests rapides
- ParallÃ©liser avec `pytest-xdist`
- Marquer les tests lents avec `@pytest.mark.slow`
- Utiliser des fixtures avec scope appropriÃ©

### Maintenance

- Mettre Ã  jour les tests lors des changements d'API
- Maintenir la couverture â‰¥ 80%
- Documenter les scÃ©narios complexes
- RÃ©viser rÃ©guliÃ¨rement les tests obsolÃ¨tes

## Ressources

- [Pytest Documentation](https://docs.pytest.org/)
- [pytest-asyncio](https://pytest-asyncio.readthedocs.io/)
- [Coverage.py](https://coverage.readthedocs.io/)
- [SQLAlchemy Testing](https://docs.sqlalchemy.org/en/20/orm/session_transaction.html#joining-a-session-into-an-external-transaction-such-as-for-test-suites)

## Support

Pour toute question ou problÃ¨me :
1. Consulter cette documentation
2. VÃ©rifier les issues GitHub existantes
3. CrÃ©er une nouvelle issue avec le label `testing`

---

**DerniÃ¨re mise Ã  jour** : 2024-01-20  
**Version** : 1.2.0  
**Couverture actuelle** : â‰¥ 80%
