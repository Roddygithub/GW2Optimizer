# GW2Optimizer - Quick Start Guide

## üöÄ Installation Rapide

### Pr√©requis
- Python 3.11+
- Node.js 18+
- Ollama ([Installation](https://ollama.ai))

### Installation Automatique

```bash
# Cloner le projet
git clone https://github.com/yourusername/GW2Optimizer.git
cd GW2Optimizer

# Ex√©cuter le script de setup
chmod +x scripts/setup.sh
./scripts/setup.sh

# Configurer les variables d'environnement
cp .env.example .env
# √âditer .env avec vos param√®tres
```

### Configuration Ollama

```bash
# D√©marrer Ollama
ollama serve

# Dans un autre terminal, t√©l√©charger Mistral
ollama pull mistral
```

## üéØ Lancement

### Option 1: Scripts automatiques

**Terminal 1 - Backend:**
```bash
./scripts/start-backend.sh
```

**Terminal 2 - Frontend:**
```bash
./scripts/start-frontend.sh
```

### Option 2: Lancement manuel

**Backend:**
```bash
cd backend
source venv/bin/activate
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

**Frontend:**
```bash
cd frontend
npm run dev
```

## üìç Acc√®s

- **Frontend**: http://localhost:5173
- **Backend API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs
- **API Redoc**: http://localhost:8000/redoc

## üß™ Tests

```bash
# Tous les tests
./scripts/run-tests.sh

# Backend uniquement
cd backend
pytest -v

# Avec couverture
pytest --cov=app --cov-report=html
```

## üìñ Utilisation

### 1. Chat avec l'IA

Acc√©dez √† l'onglet **Chat** et posez vos questions :
- "Cr√©e une composition zerg pour 25 joueurs"
- "Quel est le meilleur build Guardian pour WvW ?"
- Collez un lien GW2Skill pour analyse

### 2. Cr√©er un Build

Via l'API :
```bash
curl -X POST http://localhost:8000/api/v1/builds \
  -H "Content-Type: application/json" \
  -d '{
    "profession": "Guardian",
    "game_mode": "zerg",
    "role": "support"
  }'
```

### 3. Optimiser une √âquipe

Via l'API :
```bash
curl -X POST http://localhost:8000/api/v1/teams/optimize \
  -H "Content-Type: application/json" \
  -d '{
    "game_mode": "zerg",
    "team_size": 25,
    "required_roles": {"tank": 2, "support": 5, "dps": 18}
  }'
```

### 4. Statistiques d'Apprentissage

Acc√©dez √† l'onglet **Stats** pour voir :
- Nombre de builds collect√©s
- Score de qualit√© moyen
- Distribution des sources
- Progression de l'apprentissage

## üîß Configuration Avanc√©e

### Learning Pipeline

Le pipeline d'apprentissage s'ex√©cute automatiquement :
- **Quotidien**: √Ä 3h00 (configurable dans `scheduler.py`)
- **Manuel**: Via `/api/v1/learning/pipeline/run`

### Personnalisation

√âditez les configurations dans `.env` :
```bash
# Ollama
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=mistral:latest

# Learning
MIN_QUALITY_THRESHOLD=7.0
TRAINING_INTERVAL_DAYS=7

# Storage
MAX_STORAGE_GB=5.0
ARCHIVE_THRESHOLD_DAYS=30
```

## üêõ D√©pannage

### Ollama non connect√©
```bash
# V√©rifier si Ollama tourne
curl http://localhost:11434/api/tags

# Red√©marrer Ollama
ollama serve
```

### Port d√©j√† utilis√©
```bash
# Changer le port backend dans .env
BACKEND_PORT=8001

# Changer le port frontend dans vite.config.ts
server: { port: 5174 }
```

### Erreur de d√©pendances
```bash
# Backend
cd backend
pip install --upgrade -r requirements.txt

# Frontend
cd frontend
rm -rf node_modules package-lock.json
npm install
```

## üìö Documentation Compl√®te

- [Architecture](docs/ARCHITECTURE.md)
- [API Reference](docs/API.md)
- [README](README.md)

## ü§ù Contribution

1. Fork le projet
2. Cr√©er une branche feature (`git checkout -b feature/AmazingFeature`)
3. Commit (`git commit -m 'Add AmazingFeature'`)
4. Push (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request

## üìû Support

- Issues: https://github.com/yourusername/GW2Optimizer/issues
- Discord: https://discord.gg/gw2optimizer
